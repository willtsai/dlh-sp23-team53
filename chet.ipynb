{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of Context-aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs (Lu et al., 2022)\n",
    "\n",
    "**UIUC, CS598 DL4H, Spring 2023**\n",
    "\n",
    "**Authors:** Shiyu (Sherry) Li and Wei-Lun (Will) Tsai; {shiyuli2, wltsai2}@illinois.edu\n",
    "\n",
    "**Original paper:** Chang Lu, Tian Han, and Yue Ning. 2022. [Context-aware Health Event Prediction\n",
    "via Transition Functions on Dynamic Disease\n",
    "Graphs.](https://arxiv.org/pdf/2112.05195.pdf) Proceedings of the AAAI\n",
    "Conference on Artificial Intelligence, 36(4):4567â€“4574.\n",
    "\n",
    "**Original codebase:** [github.com/LuChang-CS/Chet](https://github.com/LuChang-CS/Chet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data\n",
    "\n",
    "As a part of the initial setup described in the [README](https://github.com/willtsai/uiuc-cs598-dlh/blob/main/README.md), we have downloaded the raw data and placed it in the `data` directory. We will now preprocess the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing the csv file of admission ...\n",
      "\t58976 in 58976 rows\n",
      "parsing csv file of diagnosis ...\n",
      "\t651047 in 651047 rows\n",
      "calibrating patients by admission ...\n",
      "calibrating admission by patients ...\n",
      "saving parsed data ...\n",
      "patient num: 7493\n",
      "max admission num: 42\n",
      "mean admission num: 2.66\n",
      "max code num in an admission: 39\n",
      "mean code num in an admission: 13.06\n",
      "max code num in a visit: 39\n",
      "encoding code ...\n",
      "There are 4880 codes\n",
      "generating code levels ...\n",
      "\t100%00%\n",
      "There are 6000 train, 493 valid, 1000 test samples\n",
      "generating code code adjacent matrix ...\n",
      "\t6000 / 6000\n",
      "building train codes features and labels ...\n",
      "\t6000 / 6000\n",
      "building valid codes features and labels ...\n",
      "\t493 / 493\n",
      "building test codes features and labels ...\n",
      "\t1000 / 1000\n",
      "building train codes features and labels for CGL...\n",
      "building train/valid/test codes features and labels for CGL...\n",
      "\t6000 / 6000\n",
      "building valid codes features and labels for CGL...\n",
      "building train/valid/test codes features and labels for CGL...\n",
      "\t493 / 493\n",
      "building test codes features and labels for CGL...\n",
      "building train/valid/test codes features and labels for CGL...\n",
      "\t1000 / 1000\n",
      "generating train neighbors ...\n",
      "\t6000 / 6000\n",
      "generating valid neighbors ...\n",
      "\t493 / 493\n",
      "generating test neighbors ...\n",
      "\t1000 / 1000\n",
      "generating train middles ...\n",
      "\t6000 / 6000\n",
      "generating valid middles ...\n",
      "\t493 / 493\n",
      "generating test middles ...\n",
      "\t1000 / 1000\n",
      "building train heart failure labels ...\n",
      "building valid heart failure labels ...\n",
      "building test heart failure labels ...\n",
      "saving encoded data ...\n",
      "saving standard data ...\n",
      "\tsaving training data\n",
      "\tsaving valid data\n",
      "\tsaving test data\n",
      "loading ICD-10 to ICD-9 map ...\n",
      "loading patients anchor year ...\n",
      "parsing the csv file of admission ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['admittime', 'hadm_id', 'subject_id']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrun_preprocess\u001b[39;00m \u001b[39mimport\u001b[39;00m pre_process\n\u001b[0;32m----> 3\u001b[0m pre_process(dataset_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mmimic3\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mmimic4\u001b[39;49m\u001b[39m'\u001b[39;49m], data_saved\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m***processing complete***\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/uiuc/dlh-sp23-team53/run_preprocess.py:57\u001b[0m, in \u001b[0;36mpre_process\u001b[0;34m(dataset_names, data_saved)\u001b[0m\n\u001b[1;32m     55\u001b[0m parser \u001b[39m=\u001b[39m conf[dataset][\u001b[39m'\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m'\u001b[39m](raw_path)\n\u001b[1;32m     56\u001b[0m sample_num \u001b[39m=\u001b[39m conf[dataset]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msample_num\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 57\u001b[0m patient_admission, admission_codes \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mparse(sample_num)\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msaving parsed data ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(parsed_path):\n",
      "File \u001b[0;32m~/repos/uiuc/dlh-sp23-team53/preprocess/parse_csv.py:135\u001b[0m, in \u001b[0;36mEHRParser.parse\u001b[0;34m(self, sample_num, seed)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m, sample_num\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, seed\u001b[39m=\u001b[39m\u001b[39m6669\u001b[39m):\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_admission()\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_diagnoses()\n\u001b[1;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalibrate_patient_by_admission()\n",
      "File \u001b[0;32m~/repos/uiuc/dlh-sp23-team53/preprocess/parse_csv.py:41\u001b[0m, in \u001b[0;36mEHRParser.parse_admission\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mparsing the csv file of admission ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m filename, cols, converters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_admission()\n\u001b[0;32m---> 41\u001b[0m admissions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, filename), usecols\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(cols\u001b[39m.\u001b[39;49mvalues()), converters\u001b[39m=\u001b[39;49mconverters)\n\u001b[1;32m     42\u001b[0m admissions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_read_admission(admissions, cols)\n\u001b[1;32m     43\u001b[0m all_patients \u001b[39m=\u001b[39m OrderedDict()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1236\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1236\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1237\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:131\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mset\u001b[39m(usecols)\u001b[39m.\u001b[39missubset(\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names\n\u001b[1;32m    130\u001b[0m ):\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_usecols_names(usecols, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morig_names)\n\u001b[1;32m    133\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(usecols):  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:913\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    911\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[1;32m    912\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 913\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m     )\n\u001b[1;32m    918\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['admittime', 'hadm_id', 'subject_id']"
     ]
    }
   ],
   "source": [
    "from run_preprocess import pre_process\n",
    "\n",
    "pre_process(dataset_names=['mimic3','mimic4'], data_saved=False)\n",
    "print('***processing complete***')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Set hyperparameters and seed\n",
    "\n",
    "We keep the same hyperparameters and seed as the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Keep the same hyperparameters and seed as the original paper\n",
    "code_size = 48\n",
    "graph_size = 32\n",
    "hidden_size = 150  # rnn hidden size\n",
    "t_attention_size = 32\n",
    "t_output_size = hidden_size\n",
    "batch_size = 32\n",
    "seed = 6669\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Config for hardware to use\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "#     device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Here we implement the model and its layers as described in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Optimized dynamic graph layer\n",
    "\n",
    "Here we define the optimized dynamic graph layer for the model. This layer performs the following steps:\n",
    "- Aggregate global/local context with the optimized graph layer with the embedding matrices\n",
    "- Calculate hidden embeddings for diagnoses and neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphLayer(nn.Module):\n",
    "    def __init__(self, adj, code_num, code_size, graph_size):\n",
    "        super().__init__()\n",
    "        self.embedding =  nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(code_num, code_size)))\n",
    "        self.adj = adj \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(code_size, graph_size)\n",
    "        self.LeakyReLU = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, code_x, neighbor):\n",
    "        # embedding matrices for for diseases appearing in current diagnoses\n",
    "        # M_embedding_matrices = self.embedding(code_x)\n",
    "        # embedding matrices for for diseases appearing in direct neighbors\n",
    "        # N_embedding_matrices = self.embedding(neighbor)\n",
    "        # static adjacency matrix\n",
    "        # keep these unsqueeze for now, may need change if we change the data loader\n",
    "        center_codes = torch.unsqueeze(code_x, dim=-1)\n",
    "        neighbor_codes = torch.unsqueeze(neighbor, dim=-1)\n",
    "\n",
    "        center_embeddings = center_codes * self.embedding\n",
    "        neighbor_embeddings = neighbor_codes * self.embedding\n",
    "\n",
    "        adj_mul_center = torch.matmul(self.adj, center_embeddings)\n",
    "        adj_mul_neighbor = torch.matmul(self.adj, neighbor_embeddings)\n",
    "\n",
    "        # All the calculation here are using the memory-efficient calculation as proved by the author in Subgraphs' Adjacency Matrix Calculation\n",
    "        # aggregated diagnosis local context and diagnosis global context\n",
    "        aggregated_diagnosis_embedding = center_embeddings + center_codes * adj_mul_center + center_codes * adj_mul_neighbor\n",
    "        # aggregated neighbor global context\n",
    "        aggregated_neighbor_embedding = neighbor_embeddings + neighbor_codes * adj_mul_neighbor + neighbor_codes * adj_mul_center\n",
    "\n",
    "        # hidden embeddings of diagnoses and neighbors\n",
    "        hidden_diagnosis_embedding = self.LeakyReLU(self.fc(aggregated_diagnosis_embedding))\n",
    "        hidden_neighbor_embedding = self.LeakyReLU(self.fc(aggregated_neighbor_embedding))\n",
    "        return hidden_diagnosis_embedding, hidden_neighbor_embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transition functions layer\n",
    "\n",
    "Here we define the transition functions layer for the model. The hidden embeddings from the optimized dynamic graph layer are used as inputs to this layer. This layer includes GRU, M-GRU (customized GRU for matrices), and single headed attention functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SingleHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, query_size, key_size, value_size, attention_size):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        self.query_dense = nn.Linear(query_size, attention_size)\n",
    "        self.key_dense = nn.Linear(key_size, attention_size)\n",
    "        self.value_dense = nn.Linear(query_size, value_size)\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        query = self.query_dense(q)\n",
    "        key = self.key_dense(k)\n",
    "        value = self.value_dense(v)\n",
    "        attention = torch.matmul(query, key.T) / math.sqrt(self.attention_size)\n",
    "        attention = torch.softmax(attention, dim=-1)\n",
    "        output = torch.matmul(attention, value)\n",
    "        return output\n",
    "    \n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, code_num, code_size, graph_size, hidden_size, t_attention_size, t_output_size):\n",
    "        super().__init__()\n",
    "        self.unrelated_embedding = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(code_num, graph_size)))\n",
    "        self.gru = nn.GRUCell(input_size=graph_size, hidden_size=hidden_size)\n",
    "        self.attention = SingleHeadAttentionLayer(graph_size, graph_size, t_output_size, t_attention_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.code_num = code_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.code_size = code_size\n",
    "\n",
    "    def forward(self, t, co_embeddings, divided, no_embeddings, hidden_state=None):\n",
    "        m_p, m_en, m_eu = divided[:, 0], divided[:, 1], divided[:, 2]\n",
    "        mp_idx, men_idx, meu_idx = torch.where(m_p > 0)[0], torch.where(m_en > 0)[0], torch.where(m_eu > 0)[0]\n",
    "        h_new = torch.zeros((self.code_num, self.hidden_size), dtype=co_embeddings.dtype).to(co_embeddings.device)\n",
    "        output_mp = 0\n",
    "        output_meneu = 0\n",
    "\n",
    "        if len(mp_idx) > 0:\n",
    "            h = hidden_state[mp_idx] if hidden_state is not None else None\n",
    "            h_p = self.gru(co_embeddings[mp_idx], h)\n",
    "            h_new[mp_idx] = h_p\n",
    "            output_mp, _ = torch.max(h_p, dim=-2)\n",
    "        if t == 0 or len(men_idx) + len(meu_idx) == 0:\n",
    "            output = output_mp\n",
    "        else:\n",
    "            q = torch.vstack([no_embeddings[men_idx], self.unrelated_embedding[meu_idx]])\n",
    "            v = torch.vstack([co_embeddings[men_idx], co_embeddings[meu_idx]])\n",
    "            h_tilda = self.activation(self.attention(q, q, v))\n",
    "            h_new[men_idx] = h_tilda[:len(men_idx)]\n",
    "            h_new[meu_idx] = h_tilda[len(men_idx):]\n",
    "            output_meneu, _ = torch.max(h_tilda, dim=-2)\n",
    "            if len(mp_idx) == 0:\n",
    "                output = output_meneu\n",
    "            else:\n",
    "                output, _ = torch.max(torch.vstack([output_mp, output_meneu]), dim=-2)\n",
    "\n",
    "        return output, h_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Embedding layer\n",
    "\n",
    "Here we define the embedding layer for the model, combined with the dot product attention activation for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingWithAttentionLayer(nn.Module):\n",
    "    def __init__(self, value_size, attention_size):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        # define context vector\n",
    "        self.context = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(attention_size, 1)))\n",
    "        self.linear = nn.Linear(value_size, attention_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # max pooling\n",
    "        t = self.linear(x)\n",
    "        # calculate attention score\n",
    "        score = torch.softmax(torch.matmul(t, self.context).squeeze(), dim=-1)\n",
    "        # final hidden embedding\n",
    "        output = torch.sum(x * torch.unsqueeze(score, dim=-1), dim=-2)\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Model and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.activation(self.dropout(self.linear(x)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still need further editing to integrate\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, code_num, code_size,\n",
    "                 adj, graph_size, hidden_size, t_attention_size, t_output_size,\n",
    "                 output_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.graph_layer = GraphLayer(adj, code_num, code_size, graph_size)\n",
    "        self.transition_layer = TransitionLayer(code_num, code_size, graph_size, hidden_size, t_attention_size, t_output_size)\n",
    "        self.attention = EmbeddingWithAttentionLayer(hidden_size, 32)\n",
    "        self.classifier = Classifier(hidden_size, output_size, dropout_rate)\n",
    "\n",
    "    def forward(self, code_x, divided, neighbors, lens):\n",
    "        output = []\n",
    "        for code_x_i, divided_i, neighbor_i, len_i in zip(code_x, divided, neighbors, lens):\n",
    "            no_embeddings_i_prev = None\n",
    "            output_i = []\n",
    "            h_t = None\n",
    "            for t, (c_it, d_it, n_it, len_it) in enumerate(zip(code_x_i, divided_i, neighbor_i, range(len_i))):\n",
    "                co_embeddings, no_embeddings = self.graph_layer(c_it, n_it)\n",
    "                output_it, h_t = self.transition_layer(t, co_embeddings, d_it, no_embeddings_i_prev, h_t)\n",
    "                no_embeddings_i_prev = no_embeddings\n",
    "                output_i.append(output_it)\n",
    "            output_i = self.attention(torch.vstack(output_i))\n",
    "            output.append(output_i)\n",
    "        output = torch.vstack(output)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define functions for training and evaluation\n",
    "\n",
    "### 4.1 Historical hot function\n",
    "\n",
    "We re-use the `historical_hot()` function directly from the [original codebase](https://github.com/LuChang-CS/Chet/blob/master/train.py). The function will be used later in model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_hot(code_x, code_num, lens):\n",
    "    result = np.zeros((len(code_x), code_num), dtype=int)\n",
    "    for i, (x, l) in enumerate(zip(code_x, lens)):\n",
    "        result[i] = x[l - 1]\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data loader function\n",
    "\n",
    "We create a data_loader() function to load the data needed for training and evaluating the model. The function is based on the [data loding code](https://github.com/LuChang-CS/Chet/blob/master/train.py#L45-L52) from the original authors and also re-uses several of the data loading helper functions from [`utils.py`](https://github.com/LuChang-CS/Chet/blob/master/utils.py) in the original codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_adj\n",
    "from utils import EHRDataset\n",
    "from utils import MultiStepLRScheduler\n",
    "\n",
    "def data_loader(task, dataset_path):\n",
    "    print('from {} for task {}:'.format(dataset_path, task))\n",
    "    print('loading code adjacency matrix ...')\n",
    "    code_adj = load_adj(dataset_path, device=device)\n",
    "    code_num = len(code_adj)\n",
    "    print('loading train data ...')\n",
    "    train_data = EHRDataset(os.path.join(dataset_path, \"train/\"), label=task, batch_size=batch_size, shuffle=True, device=device)\n",
    "    print('loading valid data ...')\n",
    "    valid_data = EHRDataset(os.path.join(dataset_path, \"valid/\"), label=task, batch_size=batch_size, shuffle=False, device=device)\n",
    "    print('loading test data ...')\n",
    "    test_data = EHRDataset(os.path.join(dataset_path, \"test/\"), label=task, batch_size=batch_size, shuffle=False, device=device)\n",
    "\n",
    "    return {\n",
    "        'dataset_name': dataset_path.split('/')[1],\n",
    "        'code_adj': code_adj, \n",
    "        'code_num': code_num, \n",
    "        'train_data': train_data, \n",
    "        'valid_data': valid_data, \n",
    "        'test_data': test_data, \n",
    "        }\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import format_time\n",
    "\n",
    "def train_chet(path, task, output_size, evaluate_fn, code_adj, code_num, dropout_rate, \n",
    "               train_data, valid_data, init_lr, lrs, milestones, epochs, test_historical):\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    \n",
    "    # Keep the same model param storage path as the original paper\n",
    "    param_path = os.path.join('data', 'params', path, task)\n",
    "    if not os.path.exists(param_path):\n",
    "        os.makedirs(param_path)\n",
    "\n",
    "    # Keep the same model, optimizer, and scheduler as the original paper,\n",
    "    # but slightly modified to leverage the new config dict\n",
    "    model = Model(code_num=code_num, code_size=code_size,\n",
    "                    adj=code_adj, graph_size=graph_size, hidden_size=hidden_size, t_attention_size=t_attention_size,\n",
    "                    t_output_size=t_output_size,\n",
    "                    output_size=output_size, dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = MultiStepLRScheduler(optimizer, epochs, init_lr, milestones, lrs)\n",
    "\n",
    "    # Keep the same param printing code as the original paper\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(pytorch_total_params)\n",
    "\n",
    "    # Keep the same training loop code as the original paper, but note that\n",
    "    # the train, valid, and test data will change based on the task and\n",
    "    # dataset of the current loop\n",
    "    epoch_lrs, valid_losses, mean_losses, time_costs, f1_scores, auc_or_topks = [], [], [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch %d / %d:' % (epoch + 1, epochs))\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_num = 0\n",
    "        steps = len(train_data)\n",
    "        st = time.time()\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.lrs[epoch]\n",
    "        for step in range(len(train_data)):\n",
    "            optimizer.zero_grad()\n",
    "            code_x, visit_lens, divided, y, neighbors = train_data[step]\n",
    "            output = model(code_x, divided, neighbors, visit_lens).squeeze()\n",
    "            loss = loss_fn(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * output_size * len(code_x)\n",
    "            total_num += len(code_x)\n",
    "\n",
    "            end_time = time.time()\n",
    "            remaining_time = format_time((end_time - st) / (step + 1) * (steps - step - 1))\n",
    "            print('\\r    Step %d / %d, LR: %s, remaining time: %s, loss: %.4f'\n",
    "                % (step + 1, steps, current_lr, remaining_time, total_loss / total_num), end='')\n",
    "        train_data.on_epoch_end()\n",
    "        et = time.time()\n",
    "        time_cost = format_time(et - st)\n",
    "        mean_loss = total_loss / total_num\n",
    "        print('\\r    Step %d / %d, LR: %s, time cost: %s, loss: %.4f' % (steps, steps, current_lr, time_cost, mean_loss))\n",
    "        valid_loss, f1_score, auc_or_topk = evaluate_fn(model, valid_data, loss_fn, output_size, test_historical)\n",
    "        torch.save(model.state_dict(), os.path.join(param_path, '%d.pt' % epoch))\n",
    "        epoch_lrs.append(current_lr)\n",
    "        valid_losses.append(valid_loss)\n",
    "        mean_losses.append(mean_loss)\n",
    "        time_costs.append(time_cost)\n",
    "        f1_scores.append(f1_score)\n",
    "        auc_or_topks.append(auc_or_topk)\n",
    "        \n",
    "    return {\n",
    "        'model': model,\n",
    "        'epoch_lrs': epoch_lrs,\n",
    "        'valid_losses': valid_losses,\n",
    "        'mean_losses': mean_losses,\n",
    "        'time_costs': time_costs,\n",
    "        'f1_scores': f1_scores,\n",
    "        'auc_or_topks': auc_or_topks,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Model evaluation function\n",
    "We create a `test()` function to evaluate the model on the `test_data`. We re-use the `evaluate_codes()` and `evaluate_hf()` functions directly from the original [metrics.py](https://github.com/LuChang-CS/Chet/blob/master/metrics.py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(evaluate_fn, model, test_data, loss_fn, output_size, test_historical):\n",
    "    print(\"Evaluating model on test data...\")\n",
    "    model.eval()\n",
    "    test_loss, f1_score, auc_or_topk = evaluate_fn(model, test_data, loss_fn, output_size, historical=test_historical)\n",
    "    print(\"Test loss: %s, F1 score: %s, AUC or TopK: %s\" % (test_loss, f1_score, auc_or_topk))\n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'f1_score': f1_score,\n",
    "        'auc_or_topk': auc_or_topk,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the preprocessed data\n",
    "\n",
    "Here we load the preprocessed data using the data_loader() function defined above, for both the MIMIC-III and MIMIC-IV datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Add data analysis here to explain each sub datasets eg: code_x, visit_lens, divided, y, neighbors, code_adj. Also can give an example by printing some data\n",
    "# Todo: Add some initial data analysis. 1) number/ratio of heart failure patients. 2) some statistic for neighbors\n",
    "# Possible Todo: build our own data builder using torch.utils.data.DataLoader as HWs\n",
    "\n",
    "tasks = ['h', 'm']\n",
    "mimic4_standard_path = \"data/mimic4/standard/\"\n",
    "mimic3_standard_path = \"data/mimic3/standard/\"\n",
    "mimic3_datasets, mimic4_datasets = {}, {}\n",
    "for task in tasks:\n",
    "    mimic3_datasets[task] = data_loader(task, mimic3_standard_path)\n",
    "    mimic4_datasets[task] = data_loader(task, mimic4_standard_path)\n",
    "print(\"data loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate_codes, evaluate_hf\n",
    "\n",
    "epochs = 20 # epochs = 200 in original paper\n",
    "\n",
    "train_results = {}\n",
    "test_results = {}\n",
    "\n",
    "for task in tasks:\n",
    "    dropout_rate_ = 0.45 if task == 'm' else 0.0\n",
    "    lrs_ = [1e-3, 1e-5] if task == 'm' else [1e-3, 1e-4, 1e-5]\n",
    "    milestones_ = [15, 17] if task == 'm' else [2,3,4] # [20, 30] [2, 3, 20]\n",
    "    evaluate_fn_ = evaluate_codes if task == 'm' else evaluate_hf\n",
    "    for dataset in [mimic3_datasets, mimic4_datasets]:\n",
    "        output_size_ = dataset[task]['code_num'] if task == 'm' else 1\n",
    "        print('training for %s task on %s dataset:' % (task, dataset[task]['dataset_name']))\n",
    "        train_data_ = dataset[task]['train_data']\n",
    "        valid_data_ = dataset[task]['valid_data']\n",
    "        test_data_ = dataset[task]['test_data']\n",
    "        train_results[dataset[task]['dataset_name'] + \"-\" + task] = train_chet(\n",
    "            path=dataset[task]['dataset_name'],task=task, output_size=output_size_, \n",
    "            evaluate_fn=evaluate_fn_, code_adj=dataset[task]['code_adj'], code_num=dataset[task]['code_num'], \n",
    "            dropout_rate=dropout_rate_, train_data=train_data_, valid_data=valid_data_, \n",
    "            init_lr=0.01, lrs=lrs_, milestones=milestones_, epochs=epochs, \n",
    "            test_historical=historical_hot(valid_data_.code_x, dataset[task]['code_num'], valid_data_.visit_lens)\n",
    "            )\n",
    "        test_results[dataset[task]['dataset_name'] + \"-\" + task] = test(\n",
    "            evaluate_fn=evaluate_fn_, model=train_results[dataset[task]['dataset_name'] + \"-\" + task]['model'], \n",
    "            test_data=test_data_, loss_fn=torch.nn.BCELoss(), output_size=output_size_,\n",
    "            test_historical=historical_hot(test_data_.code_x, dataset[task]['code_num'], test_data_.visit_lens)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the results here\n",
    "\n",
    "print(\"test_results = \", test_results)\n",
    "print(\"train_results = \", train_results)\n",
    "\n",
    "# import matplotlib.pylab as plt\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('chet_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7306b834e6e06fbd654ec785d993585f279ffa0a060b5378ceb65f5750836ec3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
